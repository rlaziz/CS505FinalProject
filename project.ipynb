{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><a href='https://github.com/neychev/small_DL_repo/tree/master/datasets/Multi30k'>Multi30k Datasets</a></li>\n",
    "    <li><a href='https://commonvoice.mozilla.org/en/datasets'>German Audio Datase</a></li>\n",
    "    <li><a href='https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-german'>Pretrained German SSR</a></li>\n",
    "    <li><a href='https://huggingface.co/oliverguhr/spelling-correction-german-base'>Spelling Correcter</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model was build with ChatGPT's help, a many-many-many tutorials that I simply can't include all here, but will pick the most important.\n",
    "\n",
    "And finally, with the help of my poor laptop that went through agony, pain, 43 kernel crashes, 3 blue screens, and days of debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorials Used\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        <a href='https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb'>\n",
    "            Build your own Transformer from scratch using Pytorch\n",
    "        </a>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href='https://pytorch.org/audio/stable/tutorials/speech_recognition_pipeline_tutorial.html'>\n",
    "            SPEECH RECOGNITION WITH WAV2VEC2\n",
    "        </a>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href='https://medium.com/mlearning-ai/build-speech-to-text-model-from-scratch-580bc2c107a'>\n",
    "            Build Speech to Text Model from Scratch\n",
    "        </a>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href='https://www.youtube.com/watch?v=U0s0f995w14&ab_channel=AladdinPersson'>\n",
    "            Pytorch Transformers from Scratch (Attention is all you need) | VIDEO\n",
    "        </a>\n",
    "    </li>\n",
    "<ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "<div style='display: flex; justify-content:center;'>\n",
    "    <img src='./architecture.jpg' width='90%'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_waveform(path):\n",
    "    waveform, sample_rate = torchaudio.load(path,format = path.split(\".\")[-1])\n",
    "    if sample_rate != 16000:\n",
    "        waveform = torchaudio.functional.resample(waveform, sample_rate, 16000)\n",
    "\n",
    "    return waveform\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    \n",
    "    if sampling_rate != 16000:\n",
    "        speech_array = torchaudio.functional.resample(speech_array, sampling_rate, 16000)\n",
    "\n",
    "    batch[\"speech\"] = speech_array[0].numpy()\n",
    "    batch[\"sentence\"] = batch[\"sentence\"].lower()\n",
    "    return batch\n",
    "\n",
    "def predict_speech(inputs, model, processor):\n",
    "    inputs = processor(inputs, sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(device), attention_mask=inputs.attention_mask.to(device)).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)[0]\n",
    "    return processor.decode(pred_ids)\n",
    "\n",
    "def fix_spelling(sentence,spelling_model):\n",
    "    prefix = 'correct: '\n",
    "    sentence = prefix + sentence\n",
    "    corrected = spelling_model(sentence,max_length=256)\n",
    "    return corrected[0]['generated_text']\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def translate_sentence(model, sentence, german, english, device, tokenizer, max_length=50):\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.text.lower() for token in tokenizer(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]\n",
    "\n",
    "def remove_tokens(sentence):\n",
    "    special_tokens = ['<sos>','<eos>','<unk>','<pad>']\n",
    "    sent = []\n",
    "    for token in sentence:\n",
    "        if token not in special_tokens:\n",
    "            sent.append(token)\n",
    "            \n",
    "    return sent\n",
    "\n",
    "def filter(sent, vocab,tokenizer):\n",
    "    sent = tokenizer(sent)\n",
    "    for token in sent:\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/de/validated.tsv', sep='\\t')\n",
    "df = df[['path', 'sentence']]\n",
    "df['path'] = '../data/de/clips/' + df['path'].astype(str)\n",
    "df['sentence'] = df['sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "\n",
    "german = Field(tokenize=tokenize_de, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "english = Field(\n",
    "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts=(\".de\", \".en\"), fields=(german, english)\n",
    ")\n",
    "\n",
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence'] = df['sentence'].apply(tokenize_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/de/clips/common_voice_de_38356033.mp3</td>\n",
       "      <td>[Ebenso, sind, Aktivitäten, bezüglich, der, Qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/de/clips/common_voice_de_38211356.mp3</td>\n",
       "      <td>[Ich, werde, Ihnen, das, sofort, beweisen, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/de/clips/common_voice_de_38422759.mp3</td>\n",
       "      <td>[Die, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/de/clips/common_voice_de_38194475.mp3</td>\n",
       "      <td>[Sie, selbst, tritt, dann, jeweils, nur, in, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/de/clips/common_voice_de_38194477.mp3</td>\n",
       "      <td>[Er, wohnt, in, Sigulda, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6862</th>\n",
       "      <td>../data/de/clips/common_voice_de_38436731.mp3</td>\n",
       "      <td>[Die, wirtschaftliche, Radikalkur, hat, sozial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6863</th>\n",
       "      <td>../data/de/clips/common_voice_de_38436745.mp3</td>\n",
       "      <td>[Direkt, im, Anschluss, unterschrieb, er, eine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>../data/de/clips/common_voice_de_38436747.mp3</td>\n",
       "      <td>[Was, ich, in, Zukunft, verhindert, sehen, möc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>../data/de/clips/common_voice_de_38436748.mp3</td>\n",
       "      <td>[Während, dieses, Aufenthalts, starb, er, an, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>../data/de/clips/common_voice_de_38436752.mp3</td>\n",
       "      <td>[Dabei, sollte, die, große, Bedeutung, der, In...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6867 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               path  \\\n",
       "0     ../data/de/clips/common_voice_de_38356033.mp3   \n",
       "1     ../data/de/clips/common_voice_de_38211356.mp3   \n",
       "2     ../data/de/clips/common_voice_de_38422759.mp3   \n",
       "3     ../data/de/clips/common_voice_de_38194475.mp3   \n",
       "4     ../data/de/clips/common_voice_de_38194477.mp3   \n",
       "...                                             ...   \n",
       "6862  ../data/de/clips/common_voice_de_38436731.mp3   \n",
       "6863  ../data/de/clips/common_voice_de_38436745.mp3   \n",
       "6864  ../data/de/clips/common_voice_de_38436747.mp3   \n",
       "6865  ../data/de/clips/common_voice_de_38436748.mp3   \n",
       "6866  ../data/de/clips/common_voice_de_38436752.mp3   \n",
       "\n",
       "                                               sentence  \n",
       "0     [Ebenso, sind, Aktivitäten, bezüglich, der, Qu...  \n",
       "1         [Ich, werde, Ihnen, das, sofort, beweisen, .]  \n",
       "2                                              [Die, M]  \n",
       "3     [Sie, selbst, tritt, dann, jeweils, nur, in, e...  \n",
       "4                           [Er, wohnt, in, Sigulda, .]  \n",
       "...                                                 ...  \n",
       "6862  [Die, wirtschaftliche, Radikalkur, hat, sozial...  \n",
       "6863  [Direkt, im, Anschluss, unterschrieb, er, eine...  \n",
       "6864  [Was, ich, in, Zukunft, verhindert, sehen, möc...  \n",
       "6865  [Während, dieses, Aufenthalts, starb, er, an, ...  \n",
       "6866  [Dabei, sollte, die, große, Bedeutung, der, In...  \n",
       "\n",
       "[6867 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech To Text (German)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-german were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-german and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"jonatasgrosman/wav2vec2-large-xlsr-53-german\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "acoustic_model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spelling_model = pipeline(\"text2text-generation\",model=\"oliverguhr/spelling-correction-german-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translator (German - English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_len,\n",
    "        device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "\n",
    "        # (N, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_seq_length, N = src.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(src_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(trg_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "        src_word_embedding = self.src_word_embedding(src)\n",
    "        src_position_embedding = self.src_position_embedding(src_positions)\n",
    "\n",
    "        trg_word_embedding = self.trg_word_embedding(trg)\n",
    "        trg_position_embedding = self.trg_position_embedding(trg_positions)\n",
    "\n",
    "        embed_src = self.dropout(src_word_embedding + src_position_embedding)\n",
    "        embed_trg = self.dropout(trg_word_embedding + trg_position_embedding)\n",
    "\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=trg_mask,\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = True\n",
    "learning_rate = 3e-4\n",
    "\n",
    "src_vocab_size = len(german.vocab)\n",
    "trg_vocab_size = len(english.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dropout = 0.10\n",
    "max_len = 100\n",
    "forward_expansion = 4\n",
    "src_pad_idx = english.vocab.stoi[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, patience=10, verbose=True\n",
    ")\n",
    "\n",
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
    "\n",
    "\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "\n",
    "sentence = \"ein pferd geht unter einer brücke neben einem boot.\"\n",
    "\n",
    "def decode_sentence(sentence,vocab):\n",
    "    # decode from int to string\n",
    "    return [vocab.itos[idx] for idx in sentence]\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), total=num_epochs, unit=\"epoch\", desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "\n",
    "        output = model(inp_data, target[:-1, :])\n",
    "\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    print(f\"Mean loss at epoch {epoch} is {mean_loss:.5f}\")\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(valid_iterator):\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        output = model(inp_data, target[:-1, :])\n",
    "\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "    print(f\"Validation loss at epoch {epoch} is {loss:.5f}\")\n",
    "\n",
    "\n",
    "    avg_val_loss = sum(val_loss) / len(val_loss)\n",
    "\n",
    "    if avg_val_loss < best_valid_loss:\n",
    "        print(f\"Saving model at epoch {epoch}\")\n",
    "        print(f\"Validation loss decreased from {best_valid_loss:.5f} to {avg_val_loss:.5f}\")\n",
    "        best_valid_loss = avg_val_loss\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = df[df['sentence'].apply(lambda x: filter(x, tokenizer=tokenize_de, vocab=german.vocab.stoi))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = sampled.apply(speech_file_to_array_fn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled['predicted'] = sampled['speech'].apply(lambda x: predict_speech(x, acoustic_model, processor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [03:00<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "sampled['predicted_fixed'] = sampled['predicted'].progress_apply(lambda x: fix_spelling(x,spelling_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>speech</th>\n",
       "      <th>predicted</th>\n",
       "      <th>predicted_fixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/de/clips/common_voice_de_38422759.mp3</td>\n",
       "      <td>die m</td>\n",
       "      <td>[1.33550524e-14, 2.0671935e-13, 1.0357326e-13,...</td>\n",
       "      <td>die m</td>\n",
       "      <td>Die M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>../data/de/clips/common_voice_de_38272068.mp3</td>\n",
       "      <td>was genau soll das sein?</td>\n",
       "      <td>[-3.4281543e-13, -4.872646e-14, 1.5407771e-12,...</td>\n",
       "      <td>was genau soll das sein</td>\n",
       "      <td>Was genau soll das sein?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>../data/de/clips/common_voice_de_38174091.mp3</td>\n",
       "      <td>das kann so nicht bleiben.</td>\n",
       "      <td>[-9.74852e-12, -9.262564e-12, 2.2325806e-11, -...</td>\n",
       "      <td>das kanns so nicht bleiben</td>\n",
       "      <td>Das kann so nicht bleiben.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>../data/de/clips/common_voice_de_38174095.mp3</td>\n",
       "      <td>dabei wurde ein bauarbeiter getötet und drei w...</td>\n",
       "      <td>[3.5853782e-15, -3.357858e-16, -1.2464322e-14,...</td>\n",
       "      <td>dabei wurde ein bauarbeiter getötet und drei w...</td>\n",
       "      <td>Dabei wurde ein Bauarbeiter getötet und drei w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>../data/de/clips/common_voice_de_38181894.mp3</td>\n",
       "      <td>im dorf befindet sich auch eine fabrik.</td>\n",
       "      <td>[2.657345e-15, -1.9893757e-15, 6.4312305e-16, ...</td>\n",
       "      <td>im dorf befindet sich auch eine fabrik</td>\n",
       "      <td>Im Dorf befindet sich auch eine Fabrik.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>../data/de/clips/common_voice_de_38395163.mp3</td>\n",
       "      <td>da wäre ich sehr traurig.</td>\n",
       "      <td>[-6.2494054e-16, 4.5298488e-15, 6.5760656e-15,...</td>\n",
       "      <td>da wäre ich sehr traurig</td>\n",
       "      <td>Da wäre ich sehr traurig.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6716</th>\n",
       "      <td>../data/de/clips/common_voice_de_38395204.mp3</td>\n",
       "      <td>ihre kleinen augen stehen weit oben am kopf.</td>\n",
       "      <td>[1.7646292e-14, 4.405076e-14, 7.24041e-14, 2.1...</td>\n",
       "      <td>ihre kleinen augen stehen weit oben am kopf</td>\n",
       "      <td>Ihre kleinen Augen stehen weit oben am Kopf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6833</th>\n",
       "      <td>../data/de/clips/common_voice_de_38436640.mp3</td>\n",
       "      <td>genau das ist richtig!</td>\n",
       "      <td>[2.5489205e-12, 9.356387e-12, 4.0864946e-12, 1...</td>\n",
       "      <td>genau das ist richtig</td>\n",
       "      <td>Genau das ist richtig.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>../data/de/clips/common_voice_de_38436641.mp3</td>\n",
       "      <td>drei hunde sind einfach zu viele.</td>\n",
       "      <td>[2.385959e-13, -7.5150205e-13, -1.7912293e-12,...</td>\n",
       "      <td>drei hunde sind einfach zu viele</td>\n",
       "      <td>Drei Hunde sind einfach zu viele.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>../data/de/clips/common_voice_de_38436702.mp3</td>\n",
       "      <td>wir tun das.</td>\n",
       "      <td>[-3.3044086e-13, 3.78819e-12, 3.146773e-12, -1...</td>\n",
       "      <td>wir tun das</td>\n",
       "      <td>Wir tun das.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               path  \\\n",
       "2     ../data/de/clips/common_voice_de_38422759.mp3   \n",
       "22    ../data/de/clips/common_voice_de_38272068.mp3   \n",
       "78    ../data/de/clips/common_voice_de_38174091.mp3   \n",
       "80    ../data/de/clips/common_voice_de_38174095.mp3   \n",
       "218   ../data/de/clips/common_voice_de_38181894.mp3   \n",
       "...                                             ...   \n",
       "6682  ../data/de/clips/common_voice_de_38395163.mp3   \n",
       "6716  ../data/de/clips/common_voice_de_38395204.mp3   \n",
       "6833  ../data/de/clips/common_voice_de_38436640.mp3   \n",
       "6834  ../data/de/clips/common_voice_de_38436641.mp3   \n",
       "6854  ../data/de/clips/common_voice_de_38436702.mp3   \n",
       "\n",
       "                                               sentence  \\\n",
       "2                                                 die m   \n",
       "22                             was genau soll das sein?   \n",
       "78                           das kann so nicht bleiben.   \n",
       "80    dabei wurde ein bauarbeiter getötet und drei w...   \n",
       "218             im dorf befindet sich auch eine fabrik.   \n",
       "...                                                 ...   \n",
       "6682                          da wäre ich sehr traurig.   \n",
       "6716       ihre kleinen augen stehen weit oben am kopf.   \n",
       "6833                             genau das ist richtig!   \n",
       "6834                  drei hunde sind einfach zu viele.   \n",
       "6854                                       wir tun das.   \n",
       "\n",
       "                                                 speech  \\\n",
       "2     [1.33550524e-14, 2.0671935e-13, 1.0357326e-13,...   \n",
       "22    [-3.4281543e-13, -4.872646e-14, 1.5407771e-12,...   \n",
       "78    [-9.74852e-12, -9.262564e-12, 2.2325806e-11, -...   \n",
       "80    [3.5853782e-15, -3.357858e-16, -1.2464322e-14,...   \n",
       "218   [2.657345e-15, -1.9893757e-15, 6.4312305e-16, ...   \n",
       "...                                                 ...   \n",
       "6682  [-6.2494054e-16, 4.5298488e-15, 6.5760656e-15,...   \n",
       "6716  [1.7646292e-14, 4.405076e-14, 7.24041e-14, 2.1...   \n",
       "6833  [2.5489205e-12, 9.356387e-12, 4.0864946e-12, 1...   \n",
       "6834  [2.385959e-13, -7.5150205e-13, -1.7912293e-12,...   \n",
       "6854  [-3.3044086e-13, 3.78819e-12, 3.146773e-12, -1...   \n",
       "\n",
       "                                              predicted  \\\n",
       "2                                                 die m   \n",
       "22                              was genau soll das sein   \n",
       "78                           das kanns so nicht bleiben   \n",
       "80    dabei wurde ein bauarbeiter getötet und drei w...   \n",
       "218              im dorf befindet sich auch eine fabrik   \n",
       "...                                                 ...   \n",
       "6682                           da wäre ich sehr traurig   \n",
       "6716        ihre kleinen augen stehen weit oben am kopf   \n",
       "6833                              genau das ist richtig   \n",
       "6834                   drei hunde sind einfach zu viele   \n",
       "6854                                        wir tun das   \n",
       "\n",
       "                                        predicted_fixed  \n",
       "2                                                Die M.  \n",
       "22                             Was genau soll das sein?  \n",
       "78                           Das kann so nicht bleiben.  \n",
       "80    Dabei wurde ein Bauarbeiter getötet und drei w...  \n",
       "218             Im Dorf befindet sich auch eine Fabrik.  \n",
       "...                                                 ...  \n",
       "6682                          Da wäre ich sehr traurig.  \n",
       "6716       Ihre kleinen Augen stehen weit oben am Kopf.  \n",
       "6833                             Genau das ist richtig.  \n",
       "6834                  Drei Hunde sind einfach zu viele.  \n",
       "6854                                       Wir tun das.  \n",
       "\n",
       "[155 rows x 5 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:22<00:00,  6.94it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "sampled['translated'] = sampled['predicted_fixed'].progress_apply(lambda x: translate_sentence(model, x, german, english, device, spacy_de, max_length=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled['translated'] = sampled['translated'].apply(lambda x: ' '.join(x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>speech</th>\n",
       "      <th>predicted</th>\n",
       "      <th>predicted_fixed</th>\n",
       "      <th>translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/de/clips/common_voice_de_38422759.mp3</td>\n",
       "      <td>die m</td>\n",
       "      <td>[1.33550524e-14, 2.0671935e-13, 1.0357326e-13,...</td>\n",
       "      <td>die m</td>\n",
       "      <td>Die M.</td>\n",
       "      <td>the &lt;unk&gt; is &lt;unk&gt; . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>../data/de/clips/common_voice_de_38272068.mp3</td>\n",
       "      <td>was genau soll das sein?</td>\n",
       "      <td>[-3.4281543e-13, -4.872646e-14, 1.5407771e-12,...</td>\n",
       "      <td>was genau soll das sein</td>\n",
       "      <td>Was genau soll das sein?</td>\n",
       "      <td>a person is looking at his board . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>../data/de/clips/common_voice_de_38174091.mp3</td>\n",
       "      <td>das kann so nicht bleiben.</td>\n",
       "      <td>[-9.74852e-12, -9.262564e-12, 2.2325806e-11, -...</td>\n",
       "      <td>das kanns so nicht bleiben</td>\n",
       "      <td>Das kann so nicht bleiben.</td>\n",
       "      <td>the &lt;unk&gt; is using n't tools . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>../data/de/clips/common_voice_de_38174095.mp3</td>\n",
       "      <td>dabei wurde ein bauarbeiter getötet und drei w...</td>\n",
       "      <td>[3.5853782e-15, -3.357858e-16, -1.2464322e-14,...</td>\n",
       "      <td>dabei wurde ein bauarbeiter getötet und drei w...</td>\n",
       "      <td>Dabei wurde ein Bauarbeiter getötet und drei w...</td>\n",
       "      <td>there is three men wearing a construction and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>../data/de/clips/common_voice_de_38181894.mp3</td>\n",
       "      <td>im dorf befindet sich auch eine fabrik.</td>\n",
       "      <td>[2.657345e-15, -1.9893757e-15, 6.4312305e-16, ...</td>\n",
       "      <td>im dorf befindet sich auch eine fabrik</td>\n",
       "      <td>Im Dorf befindet sich auch eine Fabrik.</td>\n",
       "      <td>a village is in the shower of a factory . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>../data/de/clips/common_voice_de_38395163.mp3</td>\n",
       "      <td>da wäre ich sehr traurig.</td>\n",
       "      <td>[-6.2494054e-16, 4.5298488e-15, 6.5760656e-15,...</td>\n",
       "      <td>da wäre ich sehr traurig</td>\n",
       "      <td>Da wäre ich sehr traurig.</td>\n",
       "      <td>there is some work very high - war . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6716</th>\n",
       "      <td>../data/de/clips/common_voice_de_38395204.mp3</td>\n",
       "      <td>ihre kleinen augen stehen weit oben am kopf.</td>\n",
       "      <td>[1.7646292e-14, 4.405076e-14, 7.24041e-14, 2.1...</td>\n",
       "      <td>ihre kleinen augen stehen weit oben am kopf</td>\n",
       "      <td>Ihre kleinen Augen stehen weit oben am Kopf.</td>\n",
       "      <td>their small eyes stand on the head . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6833</th>\n",
       "      <td>../data/de/clips/common_voice_de_38436640.mp3</td>\n",
       "      <td>genau das ist richtig!</td>\n",
       "      <td>[2.5489205e-12, 9.356387e-12, 4.0864946e-12, 1...</td>\n",
       "      <td>genau das ist richtig</td>\n",
       "      <td>Genau das ist richtig.</td>\n",
       "      <td>the &lt;unk&gt; is about . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>../data/de/clips/common_voice_de_38436641.mp3</td>\n",
       "      <td>drei hunde sind einfach zu viele.</td>\n",
       "      <td>[2.385959e-13, -7.5150205e-13, -1.7912293e-12,...</td>\n",
       "      <td>drei hunde sind einfach zu viele</td>\n",
       "      <td>Drei Hunde sind einfach zu viele.</td>\n",
       "      <td>three dogs are running in the same . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>../data/de/clips/common_voice_de_38436702.mp3</td>\n",
       "      <td>wir tun das.</td>\n",
       "      <td>[-3.3044086e-13, 3.78819e-12, 3.146773e-12, -1...</td>\n",
       "      <td>wir tun das</td>\n",
       "      <td>Wir tun das.</td>\n",
       "      <td>we are climbing the other the &lt;unk&gt; . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               path  \\\n",
       "2     ../data/de/clips/common_voice_de_38422759.mp3   \n",
       "22    ../data/de/clips/common_voice_de_38272068.mp3   \n",
       "78    ../data/de/clips/common_voice_de_38174091.mp3   \n",
       "80    ../data/de/clips/common_voice_de_38174095.mp3   \n",
       "218   ../data/de/clips/common_voice_de_38181894.mp3   \n",
       "...                                             ...   \n",
       "6682  ../data/de/clips/common_voice_de_38395163.mp3   \n",
       "6716  ../data/de/clips/common_voice_de_38395204.mp3   \n",
       "6833  ../data/de/clips/common_voice_de_38436640.mp3   \n",
       "6834  ../data/de/clips/common_voice_de_38436641.mp3   \n",
       "6854  ../data/de/clips/common_voice_de_38436702.mp3   \n",
       "\n",
       "                                               sentence  \\\n",
       "2                                                 die m   \n",
       "22                             was genau soll das sein?   \n",
       "78                           das kann so nicht bleiben.   \n",
       "80    dabei wurde ein bauarbeiter getötet und drei w...   \n",
       "218             im dorf befindet sich auch eine fabrik.   \n",
       "...                                                 ...   \n",
       "6682                          da wäre ich sehr traurig.   \n",
       "6716       ihre kleinen augen stehen weit oben am kopf.   \n",
       "6833                             genau das ist richtig!   \n",
       "6834                  drei hunde sind einfach zu viele.   \n",
       "6854                                       wir tun das.   \n",
       "\n",
       "                                                 speech  \\\n",
       "2     [1.33550524e-14, 2.0671935e-13, 1.0357326e-13,...   \n",
       "22    [-3.4281543e-13, -4.872646e-14, 1.5407771e-12,...   \n",
       "78    [-9.74852e-12, -9.262564e-12, 2.2325806e-11, -...   \n",
       "80    [3.5853782e-15, -3.357858e-16, -1.2464322e-14,...   \n",
       "218   [2.657345e-15, -1.9893757e-15, 6.4312305e-16, ...   \n",
       "...                                                 ...   \n",
       "6682  [-6.2494054e-16, 4.5298488e-15, 6.5760656e-15,...   \n",
       "6716  [1.7646292e-14, 4.405076e-14, 7.24041e-14, 2.1...   \n",
       "6833  [2.5489205e-12, 9.356387e-12, 4.0864946e-12, 1...   \n",
       "6834  [2.385959e-13, -7.5150205e-13, -1.7912293e-12,...   \n",
       "6854  [-3.3044086e-13, 3.78819e-12, 3.146773e-12, -1...   \n",
       "\n",
       "                                              predicted  \\\n",
       "2                                                 die m   \n",
       "22                              was genau soll das sein   \n",
       "78                           das kanns so nicht bleiben   \n",
       "80    dabei wurde ein bauarbeiter getötet und drei w...   \n",
       "218              im dorf befindet sich auch eine fabrik   \n",
       "...                                                 ...   \n",
       "6682                           da wäre ich sehr traurig   \n",
       "6716        ihre kleinen augen stehen weit oben am kopf   \n",
       "6833                              genau das ist richtig   \n",
       "6834                   drei hunde sind einfach zu viele   \n",
       "6854                                        wir tun das   \n",
       "\n",
       "                                        predicted_fixed  \\\n",
       "2                                                Die M.   \n",
       "22                             Was genau soll das sein?   \n",
       "78                           Das kann so nicht bleiben.   \n",
       "80    Dabei wurde ein Bauarbeiter getötet und drei w...   \n",
       "218             Im Dorf befindet sich auch eine Fabrik.   \n",
       "...                                                 ...   \n",
       "6682                          Da wäre ich sehr traurig.   \n",
       "6716       Ihre kleinen Augen stehen weit oben am Kopf.   \n",
       "6833                             Genau das ist richtig.   \n",
       "6834                  Drei Hunde sind einfach zu viele.   \n",
       "6854                                       Wir tun das.   \n",
       "\n",
       "                                             translated  \n",
       "2                            the <unk> is <unk> . <eos>  \n",
       "22             a person is looking at his board . <eos>  \n",
       "78                 the <unk> is using n't tools . <eos>  \n",
       "80    there is three men wearing a construction and ...  \n",
       "218     a village is in the shower of a factory . <eos>  \n",
       "...                                                 ...  \n",
       "6682         there is some work very high - war . <eos>  \n",
       "6716         their small eyes stand on the head . <eos>  \n",
       "6833                         the <unk> is about . <eos>  \n",
       "6834         three dogs are running in the same . <eos>  \n",
       "6854        we are climbing the other the <unk> . <eos>  \n",
       "\n",
       "[155 rows x 6 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sampled[['sentence','predicted_fixed','translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>predicted_fixed</th>\n",
       "      <th>translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>die m</td>\n",
       "      <td>Die M.</td>\n",
       "      <td>the &lt;unk&gt; is &lt;unk&gt; . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>was genau soll das sein?</td>\n",
       "      <td>Was genau soll das sein?</td>\n",
       "      <td>a person is looking at his board . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>das kann so nicht bleiben.</td>\n",
       "      <td>Das kann so nicht bleiben.</td>\n",
       "      <td>the &lt;unk&gt; is using n't tools . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>dabei wurde ein bauarbeiter getötet und drei w...</td>\n",
       "      <td>Dabei wurde ein Bauarbeiter getötet und drei w...</td>\n",
       "      <td>there is three men wearing a construction and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>im dorf befindet sich auch eine fabrik.</td>\n",
       "      <td>Im Dorf befindet sich auch eine Fabrik.</td>\n",
       "      <td>a village is in the shower of a factory . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>da wäre ich sehr traurig.</td>\n",
       "      <td>Da wäre ich sehr traurig.</td>\n",
       "      <td>there is some work very high - war . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6716</th>\n",
       "      <td>ihre kleinen augen stehen weit oben am kopf.</td>\n",
       "      <td>Ihre kleinen Augen stehen weit oben am Kopf.</td>\n",
       "      <td>their small eyes stand on the head . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6833</th>\n",
       "      <td>genau das ist richtig!</td>\n",
       "      <td>Genau das ist richtig.</td>\n",
       "      <td>the &lt;unk&gt; is about . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>drei hunde sind einfach zu viele.</td>\n",
       "      <td>Drei Hunde sind einfach zu viele.</td>\n",
       "      <td>three dogs are running in the same . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>wir tun das.</td>\n",
       "      <td>Wir tun das.</td>\n",
       "      <td>we are climbing the other the &lt;unk&gt; . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "2                                                 die m   \n",
       "22                             was genau soll das sein?   \n",
       "78                           das kann so nicht bleiben.   \n",
       "80    dabei wurde ein bauarbeiter getötet und drei w...   \n",
       "218             im dorf befindet sich auch eine fabrik.   \n",
       "...                                                 ...   \n",
       "6682                          da wäre ich sehr traurig.   \n",
       "6716       ihre kleinen augen stehen weit oben am kopf.   \n",
       "6833                             genau das ist richtig!   \n",
       "6834                  drei hunde sind einfach zu viele.   \n",
       "6854                                       wir tun das.   \n",
       "\n",
       "                                        predicted_fixed  \\\n",
       "2                                                Die M.   \n",
       "22                             Was genau soll das sein?   \n",
       "78                           Das kann so nicht bleiben.   \n",
       "80    Dabei wurde ein Bauarbeiter getötet und drei w...   \n",
       "218             Im Dorf befindet sich auch eine Fabrik.   \n",
       "...                                                 ...   \n",
       "6682                          Da wäre ich sehr traurig.   \n",
       "6716       Ihre kleinen Augen stehen weit oben am Kopf.   \n",
       "6833                             Genau das ist richtig.   \n",
       "6834                  Drei Hunde sind einfach zu viele.   \n",
       "6854                                       Wir tun das.   \n",
       "\n",
       "                                             translated  \n",
       "2                            the <unk> is <unk> . <eos>  \n",
       "22             a person is looking at his board . <eos>  \n",
       "78                 the <unk> is using n't tools . <eos>  \n",
       "80    there is three men wearing a construction and ...  \n",
       "218     a village is in the shower of a factory . <eos>  \n",
       "...                                                 ...  \n",
       "6682         there is some work very high - war . <eos>  \n",
       "6716         their small eyes stand on the head . <eos>  \n",
       "6833                         the <unk> is about . <eos>  \n",
       "6834         three dogs are running in the same . <eos>  \n",
       "6854        we are climbing the other the <unk> . <eos>  \n",
       "\n",
       "[155 rows x 3 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the vocab would be much bigger, with much bigger vocab, the accuracy of the model would be much better.\n",
    "\n",
    "However, it has its own disadvantage. The model with large training data would take exponentially longer to train, or exponentially more space.\n",
    "\n",
    "Anyways, for the sentences that consist of tokens from vocab, the translation is relatevly close (according to my own knowledge of German)\n",
    "\n",
    "Overall, the model did a good job"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
